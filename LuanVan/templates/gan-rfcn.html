{% extends "master.html" %}

{% block content %}
    <div class="content-header">
        <div class="container-fluid">
        </div>
    </div>

    <div class="content" style="margin-left: 15px; margin-right: 15px;">
        <div class="row">

            <div class="col-12">
                <h5 class="text-bold text-uppercase">Phát hiện bất thường trên GAN ứng dụng mạng R-FCN</h5>
            </div>

            <div class="col-12 div-upload-file">
                <div class="bg" style="padding: 20px; background-color: #487eb0; border-radius: 5px;">
                    <div class="style-upload"></div>
                    <div style="border: 2px dashed #e4e9f0; padding: 40px;" class="text-center ">
                        <label for="chon-file" class="text-center block">
                            <img src="static/images/upload-white.png" height="100" width="100" class="img-fluid anh-buon">
                        </label>
                        <label for="chon-file" style="color: white; font-weight: bold;" class="thong-bao">
                            Chọn tệp tin ảnh GAN
                        </label>
                        <input type="file" class="hide" id="chon-file">
                    </div>
                </div>

                <br>
                <p class="text-bold">Lựa chọn mô hình mạng</p>
                <div class="form-group custom-control-inline">
                    <div class="form-check">
                        <input class="form-check-input" type="radio" name="radio-loai" value="RFCNResNet101" checked>
                        <label class="form-check-label">RFCN ResNet101 	&nbsp;&nbsp;</label>
                    </div>
                    <div class="form-check custom-control-inline">
                        <input class="form-check-input" type="radio" name="radio-loai" value="MaskRCNNInceptionV2">
                        <label class="form-check-label">MaskRCNN Inception v2 &nbsp;&nbsp;</label>
                    </div>
                    <div class="form-check custom-control-inline">
                        <input class="form-check-input" type="radio" name="radio-loai" value="FasterResNet101">
                        <label class="form-check-label">Faster ResNet101 &nbsp;&nbsp;</label>
                    </div>
                    <div class="form-check custom-control-inline">
                        <input class="form-check-input" type="radio" name="radio-loai" value="FasterInceptionResNetV2">
                        <label class="form-check-label">Faster Inception ResNet v2 &nbsp;&nbsp;</label>
                    </div>
                </div>

                <br>
                <p style="color: black; font-weight: bold;">File dữ liệu mẫu:
                {% for item in data %}
                    <a style="font-weight: bold;" target="_blank" href="/static/dicom/gan/{{ item }}" download>
                        {{ item }},
                    </a>
                {% endfor %}
                </p>

            </div>
        </div>

        <div class="row div-nhan-dang pd-top-20">
            <div class="col-12 ">
                <div class="border-top pd-top-20"></div>
            </div>
            <div class="col-12">
                <p class="f-25 b">Kết quả Phát hiện bất thường trên ảnh</p>
                <div class="row">
                    <div class="col-md-4 div-anh-kq">
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12">
                <br>
                <h4 class="text-bold">1. PHƯƠNG PHÁP ĐỀ XUẤT</h4>

                <p>Phương pháp chúng tôi đề xuất dựa vào sự biến thiên đậm độ của chỉ số Hounsfield trên ảnh CT ở các thì chụp trước và sau khi tiêm chất cản quang, xác định vùng tổn thương trên gan một cách chính xác hỗ trợ cho việc gán nhãn dữ liệu. Các kỹ thuật học sâu như Faster R-CNN và R-FCN được sử dụng để phát hiện và phân loại tự động các vùng tổn thương trên gan. Kết quả thực nghiệm cho thấy phương pháp đề xuất với mô hình mạng Faster R-CNN đạt độ chính xác cao hơn mô hình mạng R-FCN với mAP đo được là 96%. Phương pháp này hỗ trợ hiệu quả cho các bác sĩ xác định được chính xác vị trí và phân loại tổn thương để có hướng điều trị kịp thời cho bệnh nhân.</p>

                <img style="width: 100%" src="/static/images/SCR-20220714-jgx.png" alt="">

                <p>Để giải quyết bài toán, chúng tôi đề xuất sử dụng mô hình tổng quát như hình 2. Mô hình tổng quát gồm có hai pha: Pha huấn luyện và pha kiểm thử được mô tả cụ thể như hình sau:</p>

                <h5><b>A. Pha huấn luyện</b></h5>

                <p class="text-bold">1. Tiền xử lý</p>


                <p>Giai đoạn này được thực hiện bằng cách chuyển đổi ảnh CT theo định dạng DICOM về các ảnh jpg, chuẩn hóa ảnh với kích thước 512×512 tương ứng với từng lát cắt và chỉ quan tâm đến các lát cắt có chứa tổn thương. Để gán nhãn cho mỗi ảnh chúng tôi dựa vào chỉ số Hounsfield hiển thị trên ảnh chụp CT, sự biến thiên đậm độ của tổn thương qua các thì chụp ảnh CT như bảng 1, tiến hành gán nhãn dữ liệu với sự hỗ trợ từ các bác sĩ chuyên khoa và tool là labelmg (hình 3 (a)). Các vùng tổn thương được gán nhãn thành một trong ba lớp: Nang gan (ký hiệu nhãn là NAN), u mạch máu Hemangioma (ký hiệu nhãn là HEM), u nguyên phát HCC (ký hiệu nhãn là HCC).</p>

                <img style="width: 100%" src="/static/images/SCR-20220714-jyz.png" alt="">

                <p class="text-bold">2. Rút trích đặc trưng</p>

                <p>Sau khi tiến hành tiền xử lý dữ liệu chúng tôi sẽ tiến hành rút trích đặc trưng. Khi đưa ảnh Train vào để huấn luyện, từng ảnh sẽ được qua các mạng rút trích đặc trưng để rút trích ra các đặc trưng tương ứng. Chúng tôi đề xuất phương pháp rút trích đặc trưng với hai mô hình mạng là Inception-ResNet-V2 và ResNet-101 như đã trình bày ở Mục 1 và Mục 2 phần C của II trong bài báo này.</p>

                <p class="text-bold">3. Huấn luyện</p>

                <p>Ở giai đoạn này, tập dữ liệu sau khi rút trích đặc trưng sẽ được huấn luyện trên hai mô hình mạng Faster R- CNN và R-FCN. Do hạn chế về tập dữ liệu thực nghiệm, chúng tôi sử dụng lại mô hình Faster R-CNN và R-FCN để có thể sử dụng được transfer learning từ bộ trọng số (weights) được trích xuất sẵn của mô hình. Điều này giúp cho việc học các đặc trưng mới nhanh hơn, rút ngắn được thời gian huấn luyện và không cần đòi hỏi tập dữ liệu lớn. Mỗi mô hình mạng như vậy sẽ tiến hành huấn luyện trên cả bốn tập Plain, Arterial, Venous và Delay, trên cùng một môi trường giống nhau, trong quá trình huấn luyện khi chỉ số Loss không được cải thiện (không giảm) chúng tôi sẽ đưa ra quyết định dừng huấn luyện và chuyển sang giai đoạn kiểm thử để so sánh, đánh giá mô hình.</p>

                 <h5><b>B. Pha kiểm thử</b></h5>

                <p>Ở giai đoạn tiền xử lý chúng tôi cũng dựa vào sự biến thiên đậm độ HU để xác định được vùng gan tổn thương, sử dụng các kỹ thuật xử lý ảnh để làm rõ các tổn thương hơn. Giai đoạn rút trích đặc trưng thực hiện tương tự như trong pha huấn luyện. Ảnh sau khi đã rút trích đặc trưng sẽ được đưa qua mô hình đã được huấn luyện trước đó để cho ra kết quả dò tìm tự động các tổn thương gồm bounding box chứa tổn thương và nhãn của tổn thương.</p>

                <h4 class="text-bold">2. KIỂM THỬ VỀ ĐỘ CHÍNH XÁC VÀ THỜI GIAN NHẬN DẠNG</h4>

                <p>Để đánh giá mô hình chúng tôi dựa vào các độ đo Loss_value, thời gian huấn luyện, AP và mAP của mô hình. Với hai kịch bản huấn luyện như đã trình bày thu được kết quả đánh giá như sau:</p>

                <p class="text-bold">a) Độ do Loss</p>

                <p class="text-center" ><img style="width: 90%" src="/static/images/SCR-20220714-k1f.png" alt=""></p>

                <p class="text-bold">b) Độ đo AP và mAP</p>
                <p class="text-bold">c) Kết quả dò tìm và phân loại tổn thương</p>

                <p>Kết quả phát hiện và phân loại tự động tổn thương với mô hình Faster R-CNN trong kịch bản 1 và R-FCN trong kịch bản 2 như đề xuất, cho kết quả với thang đo AP và mAP trên bốn tập ảnh được mô tả ở biểu đồ như hình bên dưới:</p>

                <p class="text-center" ><img style="width: 90%" src="/static/images/SCR-20220714-k46.png" alt=""></p>

                <p class="text-bold">c) Kết quả dò tìm và phân loại tổn thương</p>

                <p>Một số hình ảnh thực nghiệm khi dò tìm và phân loại tự động tổn thương trên gan của hai kịch bản đề xuất được trình bày trong bảng sau:</p>

                <p class="text-center" ><img style="width: 90%" src="/static/images/SCR-20220714-k5j.png" alt=""></p>


                <h4 class="text-bold">3. KẾT LUẬN</h4>

                <p>Trong nghiên cứu này, chúng tôi đề xuất một hướng tiếp cận mới là dựa trên chỉ số HU một chỉ số có giá trị quan trọng trên ảnh CT, để xác định vùng tổn thương hỗ trợ gán nhãn chính xác cho tập dữ liệu thực nghiệm, áp dụng các kỹ thuật mạng học sâu Faster R-CNN và R-FCN để dò tìm và phân loại các tổn thương thường gặp trên gan. Kết quả thực nghiệm cho thấy, độ chính xác của mô hình dò tìm và phân loại tổn thương bằng mạng Faster R-CNN với mạng rút trích đặc trưng Inception-ResNet-V2 có trung bình mAP đo được là 96% và mạng R-FCN với mạng rút trích đặc trưng ResNet-101 trung bình mAP là 94%. Tuy nhiên, nghiên cứu này còn hạn chế về thời gian huấn luyện mô hình. Chúng tôi sẽ tiếp tục nghiên cứu các phương pháp cải tiến thời gian huấn luyện cho mô hình bằng phương pháp xử lí song song.
</p>

                <br>
                <br>
            </div>
        </div>


    </div>

{% endblock %}

{% block script %}
<script type="text/javascript">
        var thong_tin = {
            filename: '',
            url: 'http://cangpa.vlute.edu.vn/api/gan'
        }

        $(document).ready(function () {
            $('.div-nhan-dang').hide();
        });

        $('#chon-file').change(function () {
            $('.content').waitMe({});
            $('.div-nhan-dang').hide();
            var formData = new FormData();
            formData.append("filename", document.getElementById("chon-file").files[0]);
            formData.append("loai", $('input[name="radio-loai"]:checked').val());
            $.ajax({
                url: thong_tin.url + "/upload",
                type: 'POST',
                data: formData,
                contentType: false,
                processData: false,
                xhr: function () {
                    var xhr = $.ajaxSettings.xhr();
                    xhr.upload.onprogress = function (e) {
                        var giaTri = Math.floor(e.loaded / e.total * 100);
                        $('.style-upload').css('width', 'calc(' + giaTri + '% + 40px)');
                    };
                    return xhr;
                },
                success: function (response) {
                    $('.content').waitMe("hide");
                     var tmp = "data:image/png;base64, " + response;
                     $('.div-anh-kq').append('<img src="' + tmp + '" style="width: 350px;" class="border img-fluid text-center border-radius-10 kq">');
                     $('.div-nhan-dang').show();
                },
                error: function (error) {
                    console.log(error);
                }
            });
        });

    </script>
{% endblock %}
