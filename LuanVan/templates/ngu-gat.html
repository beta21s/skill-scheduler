{% extends "master.html" %}

{% block content %}
    <div class="content-header">
        <div class="container-fluid">
        </div>
    </div>

    <div class="content" style="margin-left: 15px; margin-right: 15px;">
        <div class="row">

            <div class="col-12">
                <h5 class="text-bold text-uppercase">Phát hiện ngủ gật ứng dụng mạng DenseNet</h5>
            </div>

            <div class="col-12 div-upload-file">
                <div class="bg" style="padding: 20px; background-color: #575fcf; border-radius: 5px;">
                    <div class="style-upload"></div>
                    <div style="border: 2px dashed #e4e9f0; padding: 40px;" class="text-center ">
                        <label for="chon-file" class="text-center block">
                            <img src="static/images/upload-white.png" height="100" width="100" class="img-fluid anh-buon">
                        </label>
                        <label for="chon-file" style="color: white; font-weight: bold;" class="thong-bao">
                            Chọn tệp tin ảnh Ngủ gật
                        </label>
                        <input type="file" class="hide" id="chon-file">
                        <button class="chon-lai hide" onclick="location.reload();">
                            <img src="static/cdn/reload.png" height="20" width="20" class="img-fluid">
                            <span style="position: relative; top: 2px; font-weight: bold;">THỬ LẠI</span>
                        </button>
                    </div>
                </div>

                <br>
                <p style="color: black; font-weight: bold;">File dữ liệu mẫu:
                {% for item in data %}
                    <a style="font-weight: bold;" target="_blank" href="/static/ngugat/{{ item }}" download>
                        {{ item }},
                    </a>
                {% endfor %}
                </p>

            </div>
        </div>

        <div class="row div-nhan-dang pd-top-20">
            <div class="col-12">
                <p class="f-25 b">Kết quả</p>
                <div class="row">
                    <div class="col-md-12 div-anh-kq">
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12">
                <p class="text-bold">Full paper: <a target="_blank" href="https://www.mdpi.com/2076-3417/11/18/8441">https://www.mdpi.com/2076-3417/11/18/8441</a></p>
                <br>
                <h4 class="text-bold">1. PHƯƠNG PHÁP ĐỀ XUẤT</h4>
                <h6 class="text-bold">
                    A.	Phương pháp 1: Dựa trên kỹ thuật xác định các điểm đặc trưng trên khuôn mặt để phát hiện ngủ gật
                </h6>
                <img style="width: 100%" src="/static/images/SCR-20220711-cyy.png" alt="">

                <h6><b>Bước 1: Tiền xử lý </b></h6>

                <p class="text-center" ><img style="width: 50%" src="/static/images/anh-2.png" alt=""></p>
                <p>Tiến hành trích xuất frame ảnh từ video đầu vào (25 frame một giây (fps)). Sau đó, tiến hành lật các ảnh thu được để cho việc xác định các điểm đặc trưng chính xác hơn.</p>

                <h6><b>Bước 2: Xác định các điểm đặc trưng</b></h6>
                <p class="text-center" ><img style="width: 50%" src="/static/images/SCR-20220711-d23.png" alt=""></p>
                <p>Chúng tôi sử dụng kỹ thuật sử dụng các điểm đặc trưng trên khuôn mặt (được trình bày ở phần IIB) để khoanh vùng và đánh dấu cấu trúc khuôn mặt. Các khuôn mặt bao gồm: mày, mắt, mũi, miệng và đường viền khuôn mặt.</p>

                <h6><b>Bước 3: Xác định ngưỡng mở mắt cho mỗi người</b></h6>
                <p class="text-center" ><img style="width: 50%" src="/static/images/SCR-20220711-d4k.png" alt=""></p>
                <p>Trong bước này chúng tôi chỉ sử dụng 32 điểm đặc trưng. Dựa vào việc xác định được điểm đặc trưng trên khuôn mặt ở bước 2, chúng tôi xác định được các tọa độ điểm mắt trái và mắt phải. Trình tự các bước thực hiện như sau.</p>

                <h6 class="text-bold">
                    B. Phương pháp 2: Phát hiện ngủ gật sử dụng phương pháp học sâu (DNN)
                </h6>
                <p>Ở phương pháp 2, bài toán phát hiện ngủ gật được chia thành 2 giai đoạn: Giai đoạn huấn luyện và giai đoạn kiểm thử.</p>
                <p class="text-center" ><img style="width: 100%" src="/static/images/SCR-20220711-d8p.png" alt=""></p>

                <h6><b>Giai đoạn 1: Huấn luyện mô hình</b></h6>
                <p>Giai đoạn huấn luyện được chia thành 3 bước chính: tiền xử lý, trích chọn đặc trưng và huấn luyện mô hình.</p>

                <h6><b>Bước 1: Tiền xử lý</b></h6>
                <p>Đầu vào của hệ thống là tập ảnh ngủ gật và không ngủ gật. Sau đó xử lý chọn lấy khuôn mặt bằng việc phát hiện khuôn mặt dựa trên khung SSD (Single Shot MultiBox Detector) và sử dụng mô hình ResNet-10 được rút gọn, sau đó chuẩn hóa về kích thước 224x224 để làm dữ liệu đầu vào cho tập huấn luyện. </p>

                <h6><b>Bước 2: Trích chọn đặc trưng và huấn luyện</b></h6>
                <p>Tận dụng những ưu điểm của 2 kiến trúc mạng đã được huấn luyện trước ResNet-50V2 và MobileNetV2 (được đề cập ở phần IIC), chúng tôi sử dụng 2 mạng này trong phương pháp đề xuất. Chúng tôi sử dụng kỹ thuật transfer-learning để huấn luyện lại hai mô hình mạng ResNet-50V2 và MobileNetV2 được huấn luyện trước với tập dữ liệu như Bing Search API, Kaggle datasets, RMFD dataset</p>

                <h6><b>Giai đoạn 2: Kiểm thử </b></h6>
                <p>Ở giai đoạn này, chúng tôi tiến hành đưa ảnh đã được xử lý để thực hiện việc nhận diện trạng thái ngủ gật thông qua việc áp dụng mô hình được huấn luyện ở Giai đoạn 1 và đưa ra kết quả.</p>

                <h4 class="text-bold">2. KIỂM THỬ VỀ ĐỘ CHÍNH XÁC VÀ THỜI GIAN NHẬN DẠNG</h4>
                <p>Dựa trên các trường hợp chúng tôi thực nghiệm bao gồm cả trường hợp ngủ gật và không ngủ gật, chúng tôi đưa ra độ chính xác của 3 kịch bản đề xuất như sau:</p>

                <p class="text-center" ><img style="width: 70%" src="/static/images/SCR-20220711-ddg.png" alt=""></p>
                <p>Dựa vào các kết quả thực nghiệm, chúng tôi đưa ra thời gian nhận dạng của ba kịch bản đề xuất như sau: Quan sát hình 15 kết quả thực nghiệm chúng tôi trình bày bao gồm cả trường hợp ngủ gật và không ngủ gật lần lượt như sau: độ chính xác của kịch bản 1 là 67%; kịch bản 2 là 89% và kịch bản 3 là 100%. Có thể thấy, kịch bản 2 và 3 vượt trội hơn hẵn kịch bản 1 về độ chính xác. Mặc khác, ta thấy thời gian nhận dạng trên ba kịch bản đề xuất lần lượt như sau: kịch bản 1 là 2.7 giây, kịch bản 2 là 4.3 giây và kịch bản 3 là 5.1 giây. Qua kết quả này, ta thấy kịch bản 1 cho ra kết quả nhanh hơn 2 kịch bản còn lại, tuy nhiên việc đưa ra kết quả nhanh chóng sẽ dẫn đến việc nhận dạng trạng thái lúc này có thể bị nhầm lẫn giữa việc chớp mắt hay nhắm mắt nhưng không phải trong thời điểm ngủ gật.</p>

                <h4 class="text-bold">3. KẾT LUẬN</h4>
                <p>Trong bài báo này, chúng tôi trình bày hai phương pháp đề xuất cho việc “Phát hiện ngủ gật khi lái xe ô tô”. Phương pháp 1 (kịch bản 1) là dựa trên kỹ thuật xác định các điểm đặc trưng trên khuôn mặt để phát hiện ngủ gật. Phương pháp thứ hai (kịch bản 2 và 3), chúng tôi sử dụng kỹ thuật Deep Neural Networks để rút trích các đặc trưng cho việc huấn luyện và phát hiện các trạng thái ngủ gật và không ngủ gật. Khi sử dụng kỹ thuật Deep Neural Network, độ chính xác của nó mang lại đạt <b>96 – 97%</b>.</p>
                <br>
                <br>
            </div>
        </div>

{% endblock %}

{% block script %}
<script type="text/javascript">
        var thong_tin = {
            filename: '',
            url: 'http://cangpa.vlute.edu.vn/api/ngu-gat'
        }

        $(document).ready(function () {
            $('.div-nhan-dang').hide();
        });

        $('#chon-file').change(function () {
            $('.content').waitMe({});
            var formData = new FormData();
            formData.append("filename", document.getElementById("chon-file").files[0]);
            $.ajax({
                url: thong_tin.url + "/upload",
                type: 'POST',
                data: formData,
                contentType: false,
                processData: false,
                xhr: function () {
                    var xhr = $.ajaxSettings.xhr();
                    xhr.upload.onprogress = function (e) {
                        var giaTri = Math.floor(e.loaded / e.total * 100);
                        $('.style-upload').css('width', 'calc(' + giaTri + '% + 40px)');
                    };
                    return xhr;
                },
                success: function (response) {
                     var tmp = "data:image/png;base64, " + response;
                     $('.div-anh-kq').append('<img src="' + tmp + '" style="width: 50%;" class="border img-fluid text-center border-radius-10 kq">');
                     $('.div-nhan-dang').show();
                     $('.content').waitMe("hide");
                },
                error: function (error) {
                    console.log(error);
                }
            });
        });

    </script>
{% endblock %}
